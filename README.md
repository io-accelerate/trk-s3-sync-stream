[![Java Version](http://img.shields.io/badge/Java-1.8-blue.svg)](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)
[![Codeship Status for julianghionoiu/s3-sync](https://img.shields.io/codeship/b617e390-006f-0135-fe1b-4ee982914aba.svg)](https://codeship.com/projects/212588)
[![Coverage Status](https://coveralls.io/repos/github/julianghionoiu/s3-sync/badge.svg?branch=master)](https://coveralls.io/github/julianghionoiu/s3-sync?branch=master)

The purpose of this library is to continuously upload (multi-part) files that are being generated in a folder.
The library is optimised for working with the video files generated by:
https://github.com/julianghionoiu/dev-screen-record


#### Configuration

Configuration for running this service should be placed in file `.private/aws-test-secrets` in Java Properties file format. For examples.

```
aws_access_key_id=ABCDEFGHIJKLM
aws_secret_access_key=ABCDEFGHIJKLM
s3_region=ap-southeast-1
s3_bucket=bucketname
s3_prefix=prefix
```

The available values are
1. `aws_access_key_id`
    This contains the access key to the AWS account.
2. `aws_secret_access_key`
    This contains the secret key to the AWS account.
3. `s3_region`
    This contains the region that holds the S3 bucket.
4. `s3_bucket`
    This contains the bucket that will store the uploaded files.
5. `s3_prefix`
    This contains optional prefix for the base storage.

#### To build and run
```
./gradlew shadowJar
java -jar ./build/libs/s3-sync-1.0-SNAPSHOT-all.jar upload -f $PATH_TO_REC/recording.mp4
```

#### Security model

The library will use the a client provided token that will be exchanged for temporary S3 credentials.
The exchange will be done through a different service which is outside the scope of this library.
For development purposes, a user with S3 read-write access can be used.


### The implementation will evolve through multiple iterations.

A. On demand file upload via command line tool
* Small file upload < 5MB
* Upload a large file using multi-part upload

B. On demand folder sync with S3 bucket via command line tool
* Detect and upload new files
* No upload if all files are in the S3 bucket

C. On demand upload of video file via command line tool (multiple runs)
* Multi-part upload video file while it is being generated
* Finalize video file upload when recording is stopped

D. Manage security lifecycle
* Read client token from file and obtain temporary S3 credentials
* Manage expiration of S3 credentials

E. Library to continuously sync folder
* Manage folder syncs on a different thread
* Provide progress feedback through Observers